{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5380830,"sourceType":"datasetVersion","datasetId":3120670}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Data Preparation","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport torch\nimport random\nimport numpy as np\nfrom tqdm import tqdm\nfrom facenet_pytorch import MTCNN\n\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-18T17:54:29.921398Z","iopub.execute_input":"2025-12-18T17:54:29.921679Z","iopub.status.idle":"2025-12-18T17:54:35.643673Z","shell.execute_reply.started":"2025-12-18T17:54:29.921657Z","shell.execute_reply":"2025-12-18T17:54:35.642775Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"RAW_ROOT = \"/kaggle/input/celeb-df-v2\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T17:57:39.663679Z","iopub.execute_input":"2025-12-18T17:57:39.664690Z","iopub.status.idle":"2025-12-18T17:57:39.668370Z","shell.execute_reply.started":"2025-12-18T17:57:39.664657Z","shell.execute_reply":"2025-12-18T17:57:39.667650Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"OUT_ROOT = \"/kaggle/working/celebdf_processed\"\nTRAIN_DIR = os.path.join(OUT_ROOT, \"train\")\nVAL_DIR   = os.path.join(OUT_ROOT, \"val\")\n\nos.makedirs(TRAIN_DIR, exist_ok=True)\nos.makedirs(VAL_DIR, exist_ok=True)\n\nmtcnn = MTCNN(\n    image_size=224,\n    margin=20,\n    select_largest=True,\n    post_process=False,   # IMPORTANT: we handle normalization ourselves\n    device=device\n)\n\ndef sample_frame_indices(total_frames, num_frames=24):\n    if total_frames <= num_frames:\n        return list(range(total_frames))\n    return np.linspace(0, total_frames - 1, num_frames).astype(int)\n\ndef extract_rgb_dct(video_path, num_frames=24):\n    cap = cv2.VideoCapture(video_path)\n    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    frame_ids = sample_frame_indices(total_frames, num_frames)\n\n    rgb_faces = []\n    dct_maps = []\n\n    for fid in frame_ids:\n        cap.set(cv2.CAP_PROP_POS_FRAMES, fid)\n        ret, frame = cap.read()\n        if not ret:\n            continue\n\n        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n\n        face = mtcnn(frame_rgb)\n        if face is None:\n            continue\n\n        # ---- RGB FACE (uint8) ----\n        face = face.clamp(0, 255).byte()\n        rgb_faces.append(face)\n\n        # ---- DCT (112x112, fp16) ----\n        gray = cv2.cvtColor(frame_rgb, cv2.COLOR_RGB2GRAY)\n        gray = cv2.resize(gray, (112, 112))\n        dct = cv2.dct(np.float32(gray))\n        dct = np.log(np.abs(dct) + 1e-6)\n        dct_maps.append(\n            torch.tensor(dct, dtype=torch.float16).unsqueeze(0)\n        )\n\n    cap.release()\n\n    if len(rgb_faces) < 5:\n        return None\n\n    return torch.stack(rgb_faces), torch.stack(dct_maps)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T17:57:40.873044Z","iopub.execute_input":"2025-12-18T17:57:40.873373Z","iopub.status.idle":"2025-12-18T17:57:41.029778Z","shell.execute_reply.started":"2025-12-18T17:57:40.873349Z","shell.execute_reply":"2025-12-18T17:57:41.028905Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def process_and_save(video_path, label, out_dir):\n    result = extract_rgb_dct(video_path)\n    if result is None:\n        return False\n\n    rgb, dct = result\n    name = os.path.splitext(os.path.basename(video_path))[0]\n\n    torch.save(\n        {\n            \"rgb\": rgb,   # uint8 (T,3,224,224)\n            \"dct\": dct,   # float16 (T,1,112,112)\n            \"label\": label\n        },\n        os.path.join(out_dir, name + \".pt\")\n    )\n    return True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T17:57:43.719666Z","iopub.execute_input":"2025-12-18T17:57:43.720416Z","iopub.status.idle":"2025-12-18T17:57:43.724696Z","shell.execute_reply.started":"2025-12-18T17:57:43.720393Z","shell.execute_reply":"2025-12-18T17:57:43.723931Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"real_videos = []\nfake_videos = []\n\nfor folder in [\"Celeb-real\", \"YouTube-real\"]:\n    path = os.path.join(RAW_ROOT, folder)\n    for f in os.listdir(path):\n        real_videos.append(os.path.join(path, f))\n\nfor f in os.listdir(os.path.join(RAW_ROOT, \"Celeb-synthesis\")):\n    fake_videos.append(os.path.join(RAW_ROOT, \"Celeb-synthesis\", f))\n\nrandom.shuffle(real_videos)\nrandom.shuffle(fake_videos)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T17:58:06.609679Z","iopub.execute_input":"2025-12-18T17:58:06.610481Z","iopub.status.idle":"2025-12-18T17:58:06.735045Z","shell.execute_reply.started":"2025-12-18T17:58:06.610456Z","shell.execute_reply":"2025-12-18T17:58:06.734433Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"TRAIN_REAL = 400\nTRAIN_FAKE = 400\nVAL_REAL   = 100\nVAL_FAKE   = 100\n\ntrain_real = real_videos[:TRAIN_REAL]\ntrain_fake = fake_videos[:TRAIN_FAKE]\n\nval_real = real_videos[TRAIN_REAL:TRAIN_REAL + VAL_REAL]\nval_fake = fake_videos[TRAIN_FAKE:TRAIN_FAKE + VAL_FAKE]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T17:58:12.795932Z","iopub.execute_input":"2025-12-18T17:58:12.796221Z","iopub.status.idle":"2025-12-18T17:58:12.800634Z","shell.execute_reply.started":"2025-12-18T17:58:12.796201Z","shell.execute_reply":"2025-12-18T17:58:12.799762Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Processing TRAIN REAL\")\nfor v in tqdm(train_real):\n    process_and_save(v, 0, TRAIN_DIR)\n\nprint(\"Processing TRAIN FAKE\")\nfor v in tqdm(train_fake):\n    process_and_save(v, 1, TRAIN_DIR)\n\nprint(\"Processing VAL REAL\")\nfor v in tqdm(val_real):\n    process_and_save(v, 0, VAL_DIR)\n\nprint(\"Processing VAL FAKE\")\nfor v in tqdm(val_fake):\n    process_and_save(v, 1, VAL_DIR)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T17:58:16.722614Z","iopub.execute_input":"2025-12-18T17:58:16.722913Z","iopub.status.idle":"2025-12-18T18:32:01.507304Z","shell.execute_reply.started":"2025-12-18T17:58:16.722893Z","shell.execute_reply":"2025-12-18T18:32:01.506545Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Train videos:\", len(os.listdir(TRAIN_DIR)))\nprint(\"Val videos:\", len(os.listdir(VAL_DIR)))\n\nsample = torch.load(os.path.join(TRAIN_DIR, os.listdir(TRAIN_DIR)[0]))\nprint(\"RGB shape:\", sample[\"rgb\"].shape, sample[\"rgb\"].dtype)\nprint(\"DCT shape:\", sample[\"dct\"].shape, sample[\"dct\"].dtype)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T19:38:20.209139Z","iopub.execute_input":"2025-12-18T19:38:20.209427Z","iopub.status.idle":"2025-12-18T19:38:20.218769Z","shell.execute_reply.started":"2025-12-18T19:38:20.209405Z","shell.execute_reply":"2025-12-18T19:38:20.217992Z"}},"outputs":[{"name":"stdout","text":"Train videos: 800\nVal videos: 200\nRGB shape: torch.Size([24, 3, 224, 224]) torch.uint8\nDCT shape: torch.Size([24, 1, 112, 112]) torch.float16\n","output_type":"stream"}],"execution_count":31},{"cell_type":"markdown","source":"# Training Part","metadata":{}},{"cell_type":"code","source":"import os\nimport random\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm import tqdm\n\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T18:40:57.721315Z","iopub.execute_input":"2025-12-18T18:40:57.721621Z","iopub.status.idle":"2025-12-18T18:40:57.727837Z","shell.execute_reply.started":"2025-12-18T18:40:57.721601Z","shell.execute_reply":"2025-12-18T18:40:57.726960Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"DATA_ROOT = \"/kaggle/working/celebdf_processed\"\nTRAIN_DIR = os.path.join(DATA_ROOT, \"train\")\nVAL_DIR   = os.path.join(DATA_ROOT, \"val\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T18:41:44.815075Z","iopub.execute_input":"2025-12-18T18:41:44.815788Z","iopub.status.idle":"2025-12-18T18:41:44.819518Z","shell.execute_reply.started":"2025-12-18T18:41:44.815760Z","shell.execute_reply":"2025-12-18T18:41:44.818605Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def sample_frames(x, num_frames=24):\n    T = x.shape[0]\n    if T <= num_frames:\n        return x\n    idx = torch.linspace(0, T - 1, num_frames).long()\n    return x[idx]\n\ndef make_windows(x, window=5, stride=4):\n    return torch.stack([\n        x[i:i+window]\n        for i in range(0, x.shape[0] - window + 1, stride)\n    ])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T18:42:08.414911Z","iopub.execute_input":"2025-12-18T18:42:08.415400Z","iopub.status.idle":"2025-12-18T18:42:08.420396Z","shell.execute_reply.started":"2025-12-18T18:42:08.415375Z","shell.execute_reply":"2025-12-18T18:42:08.419482Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"class CelebDFVideoDataset(Dataset):\n    def __init__(self, root):\n        self.files = [\n            os.path.join(root, f)\n            for f in os.listdir(root)\n            if f.endswith(\".pt\")\n        ]\n\n    def __len__(self):\n        return len(self.files)\n\n    def __getitem__(self, idx):\n        data = torch.load(self.files[idx], map_location=\"cpu\")\n\n        rgb = data[\"rgb\"].float() / 255.0     # (T,3,224,224)\n        dct = data[\"dct\"].float()             # (T,1,112,112)\n        label = torch.tensor(data[\"label\"], dtype=torch.float32)\n\n        rgb = sample_frames(rgb)\n        dct = sample_frames(dct)\n\n        rgb_w = make_windows(rgb)\n        dct_w = make_windows(dct)\n\n        return rgb_w, dct_w, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T18:42:25.707178Z","iopub.execute_input":"2025-12-18T18:42:25.707455Z","iopub.status.idle":"2025-12-18T18:42:25.713427Z","shell.execute_reply.started":"2025-12-18T18:42:25.707436Z","shell.execute_reply":"2025-12-18T18:42:25.712538Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"class PixelCNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        backbone = torchvision.models.resnet18(\n            weights=\"IMAGENET1K_V1\"\n        )\n        backbone.fc = nn.Linear(512, 256)\n        self.net = backbone\n\n    def forward(self, x):\n        B, W, C, H, W_ = x.shape\n        x = x.view(B * W, C, H, W_)\n        x = self.net(x)\n        return x.view(B, W, -1)\n\nclass DCTCNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(1, 32, 3, padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n\n            nn.Conv2d(32, 64, 3, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.AdaptiveAvgPool2d(1)\n        )\n        self.fc = nn.Linear(64, 256)\n\n    def forward(self, x):\n        B, W, C, H, W_ = x.shape \n        x = x.view(B * W, C, H, W_)\n        x = self.conv(x).squeeze(-1).squeeze(-1) # (B*W, 64, 1, 1) --> (B*W,64)\n        x = self.fc(x)\n        return x.view(B, W, -1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T18:45:20.046138Z","iopub.execute_input":"2025-12-18T18:45:20.046889Z","iopub.status.idle":"2025-12-18T18:45:20.054044Z","shell.execute_reply.started":"2025-12-18T18:45:20.046865Z","shell.execute_reply":"2025-12-18T18:45:20.053173Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"class TemporalEncoder(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.lstm = nn.LSTM(256, 256, batch_first=True)\n\n    def forward(self, x):\n        out, _ = self.lstm(x)\n        return out[:, -1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T19:51:58.120561Z","iopub.execute_input":"2025-12-18T19:51:58.120880Z","iopub.status.idle":"2025-12-18T19:51:58.125557Z","shell.execute_reply.started":"2025-12-18T19:51:58.120860Z","shell.execute_reply":"2025-12-18T19:51:58.124683Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"class VideoDeepfakeModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.pixel = PixelCNN()\n        self.dct = DCTCNN()\n\n        self.pixel_lstm = TemporalEncoder()\n        self.dct_lstm = TemporalEncoder()\n\n        self.video_lstm = nn.LSTM(512, 256, batch_first=True)\n        self.classifier = nn.Linear(256, 1)\n\n    def forward(self, rgb, dct):\n        B, N, W, C, H, W_ = rgb.shape\n\n        rgb = rgb.view(B * N, W, C, H, W_)\n        dct = dct.view(B * N, W, 1, dct.shape[-2], dct.shape[-1])\n\n        p = self.pixel_lstm(self.pixel(rgb))\n        f = self.dct_lstm(self.dct(dct))\n\n        fused = torch.cat([p, f], dim=-1)\n        fused = fused.view(B, N, -1)\n\n        v, _ = self.video_lstm(fused)\n        return self.classifier(v[:, -1]).squeeze(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T18:51:47.081539Z","iopub.execute_input":"2025-12-18T18:51:47.082058Z","iopub.status.idle":"2025-12-18T18:51:47.088126Z","shell.execute_reply.started":"2025-12-18T18:51:47.082036Z","shell.execute_reply":"2025-12-18T18:51:47.087340Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"model = VideoDeepfakeModel().to(device)\n\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = optim.AdamW(model.parameters(), lr=3e-4)\nscheduler = optim.lr_scheduler.CosineAnnealingLR(\n    optimizer, T_max=8\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T18:52:11.438428Z","iopub.execute_input":"2025-12-18T18:52:11.438870Z","iopub.status.idle":"2025-12-18T18:52:11.995752Z","shell.execute_reply.started":"2025-12-18T18:52:11.438849Z","shell.execute_reply":"2025-12-18T18:52:11.994939Z"}},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44.7M/44.7M [00:00<00:00, 185MB/s]\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"for p in model.pixel.parameters():\n    p.requires_grad = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T18:52:51.938477Z","iopub.execute_input":"2025-12-18T18:52:51.939342Z","iopub.status.idle":"2025-12-18T18:52:51.943314Z","shell.execute_reply.started":"2025-12-18T18:52:51.939317Z","shell.execute_reply":"2025-12-18T18:52:51.942478Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"def train_epoch(loader):\n    model.train()\n    correct, total, loss_sum = 0, 0, 0\n\n    for rgb, dct, y in tqdm(loader):\n        rgb = rgb.to(device)\n        dct = dct.to(device)\n        y = y.to(device)\n\n        optimizer.zero_grad()\n        logits = model(rgb, dct)\n        loss = criterion(logits, y)\n        loss.backward()\n        optimizer.step()\n\n        preds = (torch.sigmoid(logits) > 0.5).float()\n        correct += (preds == y).sum().item()\n        total += y.size(0)\n        loss_sum += loss.item()\n\n    return correct / total, loss_sum / len(loader)\n\n\ndef eval_epoch(loader):\n    model.eval()\n    correct, total = 0, 0\n\n    with torch.no_grad():\n        for rgb, dct, y in loader:\n            rgb = rgb.to(device)\n            dct = dct.to(device)\n            y = y.to(device)\n\n            logits = model(rgb, dct)\n            preds = (torch.sigmoid(logits) > 0.5).float()\n            correct += (preds == y).sum().item()\n            total += y.size(0)\n\n    return correct / total\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T18:53:14.440939Z","iopub.execute_input":"2025-12-18T18:53:14.441804Z","iopub.status.idle":"2025-12-18T18:53:14.448090Z","shell.execute_reply.started":"2025-12-18T18:53:14.441780Z","shell.execute_reply":"2025-12-18T18:53:14.447375Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"train_ds = CelebDFVideoDataset(TRAIN_DIR)\nval_ds   = CelebDFVideoDataset(VAL_DIR)\n\ntrain_loader = DataLoader(\n    train_ds,\n    batch_size=4,\n    shuffle=True,\n    num_workers=4,\n    pin_memory=True\n)\n\nval_loader = DataLoader(\n    val_ds,\n    batch_size=4,\n    shuffle=False,\n    num_workers=4,\n    pin_memory=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T18:53:52.327295Z","iopub.execute_input":"2025-12-18T18:53:52.327908Z","iopub.status.idle":"2025-12-18T18:53:52.334338Z","shell.execute_reply.started":"2025-12-18T18:53:52.327887Z","shell.execute_reply":"2025-12-18T18:53:52.333745Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"EPOCHS = 8\n\nfor epoch in range(EPOCHS):\n\n    if epoch == 4:\n        print(\"ðŸ”“ Unfreezing Pixel CNN\")\n        for p in model.pixel.parameters():\n            p.requires_grad = True\n\n    train_acc, train_loss = train_epoch(train_loader)\n    val_acc = eval_epoch(val_loader)\n    scheduler.step()\n\n    print(\n        f\"Epoch {epoch+1}/{EPOCHS} | \"\n        f\"Train Acc: {train_acc:.3f} | \"\n        f\"Val Acc: {val_acc:.3f}\"\n    )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T18:54:32.178515Z","iopub.execute_input":"2025-12-18T18:54:32.178855Z","iopub.status.idle":"2025-12-18T18:58:42.382524Z","shell.execute_reply.started":"2025-12-18T18:54:32.178833Z","shell.execute_reply":"2025-12-18T18:58:42.381588Z"}},"outputs":[{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:17<00:00, 11.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/8 | Train Acc: 0.611 | Val Acc: 0.715\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:16<00:00, 11.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/8 | Train Acc: 0.705 | Val Acc: 0.760\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:16<00:00, 11.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/8 | Train Acc: 0.714 | Val Acc: 0.685\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:17<00:00, 11.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/8 | Train Acc: 0.744 | Val Acc: 0.780\nðŸ”“ Unfreezing Pixel CNN\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:37<00:00,  5.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5/8 | Train Acc: 0.660 | Val Acc: 0.830\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:37<00:00,  5.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6/8 | Train Acc: 0.812 | Val Acc: 0.730\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:37<00:00,  5.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7/8 | Train Acc: 0.899 | Val Acc: 0.880\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:37<00:00,  5.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8/8 | Train Acc: 0.963 | Val Acc: 0.950\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"torch.save(model.state_dict(),'/kaggle/working/final_model.pt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T19:02:07.528996Z","iopub.execute_input":"2025-12-18T19:02:07.529299Z","iopub.status.idle":"2025-12-18T19:02:07.609748Z","shell.execute_reply.started":"2025-12-18T19:02:07.529280Z","shell.execute_reply":"2025-12-18T19:02:07.608894Z"}},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":"# Testing Part","metadata":{}},{"cell_type":"code","source":"TEST_DIR = os.path.join(OUT_ROOT, \"test\")\nos.makedirs(TEST_DIR, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T20:18:53.947167Z","iopub.execute_input":"2025-12-18T20:18:53.947860Z","iopub.status.idle":"2025-12-18T20:18:53.951749Z","shell.execute_reply.started":"2025-12-18T20:18:53.947837Z","shell.execute_reply":"2025-12-18T20:18:53.950875Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"TEST_REAL = 100\nTEST_FAKE = 100\n\ntest_real = real_videos[\n    TRAIN_REAL + VAL_REAL :\n    TRAIN_REAL + VAL_REAL + TEST_REAL\n]\n\ntest_fake = fake_videos[\n    TRAIN_FAKE + VAL_FAKE :\n    TRAIN_FAKE + VAL_FAKE + TEST_FAKE\n]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T20:21:57.583480Z","iopub.execute_input":"2025-12-18T20:21:57.583819Z","iopub.status.idle":"2025-12-18T20:21:57.588172Z","shell.execute_reply.started":"2025-12-18T20:21:57.583796Z","shell.execute_reply":"2025-12-18T20:21:57.587324Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"print(\"Processing TEST REAL\")\nfor v in tqdm(test_real):\n    process_and_save(v, 0, TEST_DIR)\n\nprint(\"Processing TEST FAKE\")\nfor v in tqdm(test_fake):\n    process_and_save(v, 1, TEST_DIR)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T20:22:29.114334Z","iopub.execute_input":"2025-12-18T20:22:29.115176Z","iopub.status.idle":"2025-12-18T20:29:46.518196Z","shell.execute_reply.started":"2025-12-18T20:22:29.115141Z","shell.execute_reply":"2025-12-18T20:29:46.517533Z"}},"outputs":[{"name":"stdout","text":"Processing TEST REAL\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [03:36<00:00,  2.16s/it]\n","output_type":"stream"},{"name":"stdout","text":"Processing TEST FAKE\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [03:41<00:00,  2.21s/it]\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"print(\"Test videos:\", len(os.listdir(TEST_DIR)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T20:29:53.527356Z","iopub.execute_input":"2025-12-18T20:29:53.527890Z","iopub.status.idle":"2025-12-18T20:29:53.532370Z","shell.execute_reply.started":"2025-12-18T20:29:53.527870Z","shell.execute_reply":"2025-12-18T20:29:53.531613Z"}},"outputs":[{"name":"stdout","text":"Test videos: 199\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"TEST_DIR = os.path.join(DATA_ROOT, \"test\")\n\ntest_ds = CelebDFVideoDataset(TEST_DIR)\n\ntest_loader = DataLoader(\n    test_ds,\n    batch_size=4,\n    shuffle=False,\n    num_workers=4,\n    pin_memory=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T20:30:51.101629Z","iopub.execute_input":"2025-12-18T20:30:51.102177Z","iopub.status.idle":"2025-12-18T20:30:51.106791Z","shell.execute_reply.started":"2025-12-18T20:30:51.102156Z","shell.execute_reply":"2025-12-18T20:30:51.106125Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"from sklearn.metrics import (\n    confusion_matrix,\n    accuracy_score,\n    precision_score,\n    recall_score,\n    f1_score,\n    roc_auc_score\n)\n\ndef evaluate_test(loader):\n    model.eval()\n\n    y_true = []\n    y_pred = []\n    y_prob = []\n\n    with torch.no_grad():\n        for rgb, dct, y in tqdm(loader):\n            rgb = rgb.to(device)\n            dct = dct.to(device)\n\n            logits = model(rgb, dct)\n            probs = torch.sigmoid(logits)\n\n            y_true.extend(y.numpy())\n            y_prob.extend(probs.cpu().numpy())\n            y_pred.extend((probs > 0.5).cpu().numpy())\n\n    return (\n        np.array(y_true),\n        np.array(y_pred),\n        np.array(y_prob)\n    )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T20:31:36.374556Z","iopub.execute_input":"2025-12-18T20:31:36.374928Z","iopub.status.idle":"2025-12-18T20:31:36.892437Z","shell.execute_reply.started":"2025-12-18T20:31:36.374906Z","shell.execute_reply":"2025-12-18T20:31:36.891862Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"y_true, y_pred, y_prob = evaluate_test(test_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T20:32:23.096299Z","iopub.execute_input":"2025-12-18T20:32:23.097032Z","iopub.status.idle":"2025-12-18T20:32:27.084752Z","shell.execute_reply.started":"2025-12-18T20:32:23.097009Z","shell.execute_reply":"2025-12-18T20:32:27.083884Z"}},"outputs":[{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:03<00:00, 12.56it/s]\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"acc  = accuracy_score(y_true, y_pred)\nprec = precision_score(y_true, y_pred)\nrec  = recall_score(y_true, y_pred)\nf1   = f1_score(y_true, y_pred)\nauc  = roc_auc_score(y_true, y_prob)\n\nprint(f\"Test Accuracy : {acc:.4f}\")\nprint(f\"Precision     : {prec:.4f}\")\nprint(f\"Recall        : {rec:.4f}\")\nprint(f\"F1-score      : {f1:.4f}\")\nprint(f\"AUC           : {auc:.4f}\")\n\nconfuson_Matrix = confusion_matrix(y_true, y_pred)\nprint(\"Confuson Matrix:\")\nprint(consfusion_Matrix)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T20:36:39.996334Z","iopub.execute_input":"2025-12-18T20:36:39.996628Z","iopub.status.idle":"2025-12-18T20:36:40.012986Z","shell.execute_reply.started":"2025-12-18T20:36:39.996608Z","shell.execute_reply":"2025-12-18T20:36:40.012177Z"}},"outputs":[{"name":"stdout","text":"Test Accuracy : 0.9246\nPrecision     : 0.8899\nRecall        : 0.9700\nF1-score      : 0.9282\nAUC           : 0.9779\nConfuson Matrix:\n[[87 12]\n [ 3 97]]\n","output_type":"stream"}],"execution_count":48}]}